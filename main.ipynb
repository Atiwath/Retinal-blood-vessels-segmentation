{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76500de6-f036-4945-8280-6a36bfba698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae03f4-a75a-4fca-8a12-5df20b92d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus, 'GPU')\n",
    "else:\n",
    "    raise RuntimeError(\"No GPU found, this environment requires GPU resources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0755764-a866-4540-a1be-dd6a3acb3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 256, 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "\n",
    "IMAGE_DIR = 'dataset/image'\n",
    "MASK_DIR = 'dataset/mask'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae424e2-7daa-42e1-9d78-36aec7496b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_dir, mask_dir, img_height=IMG_HEIGHT, img_width=IMG_WIDTH):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    image_paths = glob(os.path.join(image_dir, \"*.png\"))\n",
    "    mask_paths = glob(os.path.join(mask_dir, \"*.png\"))\n",
    "\n",
    "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (img_width, img_height))\n",
    "        img = img / 255.0\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (img_width, img_height))\n",
    "        mask = mask / 255.0\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "images, masks = load_images(IMAGE_DIR, MASK_DIR)\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf130c-93b7-4bdf-bcca-2dcfb7d88ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of images: {len(images)}\")\n",
    "print(f\"Number of masks: {len(masks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c4166-a20a-41db-8b0b-3a3b88482a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    merge6 = layers.concatenate([conv4, up6], axis=3)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    merge7 = layers.concatenate([conv3, up7], axis=3)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    merge8 = layers.concatenate([conv2, up8], axis=3)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    merge9 = layers.concatenate([conv1, up9], axis=3)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = unet_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa982f0-5c31-4197-9c1f-a28d825220fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split=0.1,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc8cfe-4f6f-4381-a6e8-3bf6908463ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "preds = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5f37e-3655-4882-be0f-ec75c29c23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(image, mask, prediction):\n",
    "    image_bgr = image[..., ::-1]  \n",
    "    plt.figure(figsize=(10, 3))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(mask[:, :, 0], cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(image_bgr) \n",
    "    plt.title('Ground Truth Mask')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(prediction[:, :, 0], cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for i in range(5): \n",
    "    plot_sample(x_test[i], y_test[i], preds2[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
